<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/ironman-draw.png">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <title>
        
          hadoop第一课 - 梅老板 | Blog
        
    </title>

    <link rel="canonical" href="http://www.ruozedata.com/article/hadoop第一课/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS --> 
    <link rel="stylesheet" href="/css/beantech.min.css">

    <link rel="stylesheet" href="/css/donate.css">
    
    <!-- Pygments Highlight CSS -->
    <link rel="stylesheet" href="/css/highlight.css">

    <link rel="stylesheet" href="/css/widget.css">

    <link rel="stylesheet" href="/css/rocket.css">

    <link rel="stylesheet" href="/css/signature.css">

    <link rel="stylesheet" href="/css/toc.css">

    <!-- Custom Fonts -->
    <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">
	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            background-image: url('/img/article_header/article_header.png')
            /*post*/
        
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#ruozedata" title="ruozedata">ruozedata</a>
                            
                        </div>
                        <h1>hadoop第一课</h1>
                        <h2 class="subheading">This is hexo theme Demo.</h2>
                        <span class="meta">
                            Posted by John on
                            2019-11-27
                        </span>
                    </div>
                


                </div>
            </div>
        </div>
    </div>
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">亚历山大-梅西</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    <!-- Modify by Yu-Hsuan Yen -->

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <hr>
<p><strong><a href="#id_1" target="_self">一、上次课程回顾</a></strong></p>
<p><strong><a href="#id_2" target="_self">二、hadoop入门介绍</a></strong></p>
<ul>
<li><a href="#id_2.1" target="_self">2.1 hadoop概念</a></li>
<li><a href="#id_2.2" target="_self">2.2 hadoop软件版本</a></li>
<li><a href="#id_2.3" target="_self">2.3 hadoop软件的三大组成部分</a></li>
<li><a href="#id_2.4" target="_self">2.4 hadoop下载方式</a></li>
</ul>
<p><strong><a href="#id_3" target="_self">三、hdfs部署环境</a></strong></p>
<ul>
<li><a href="#id_3.1" target="_self">3.1、账户当前不可用的解决办法</a></li>
</ul>
<p><strong><a href="#id_4" target="_self">四、hdfs伪分布式部署</a></strong></p>
<ul>
<li><a href="#id_4.1" target="_self">4.1 单台机器的无密码访问</a></li>
<li><a href="#id_4.2" target="_self">4.2 准备启动hadoop</a></li>
<li><a href="#id_4.3" target="_self">4.3 hadoop日志信息解读</a></li>
<li><a href="#id_4.4" target="_self">4.4 Web UI界面信息查看</a></li>
</ul>
<p><strong><a href="#id_5" target="_self">五、作业</a></strong></p>
<h1 id="一-上次课课程回顾">一、上次课课程回顾</h1>
1、MySQL的sql语法，需要自己去看；在大数据开发中存储过程和函数几乎用不到；做Java开发的会用的到。
<p>2、查询数据库中的视图和存储过程。</p>
<p>3、MySQL分组排序，Oracle分组排序，Spark分组排序，这些的真正含义是什么？</p>
<p>4、MySQL中的leftjoin、innerjoin</p>
<h1 id="二-hadoop入门介绍">二、hadoop入门介绍</h1>
<h1 id="21-概念">2.1、概念</h1>
1、广义：以apache hadoop软件为主的生态圈（Hive、Zookeeper、Hbase）
<p>2、狭义：指的就是hadoop软件，如</p>
<ul>
<li><a href="http://www.apache.org/index.html#projects-list%EF%BC%8C%E5%9C%A8%E8%BF%99%E4%B8%AA%E7%BD%91%E5%9D%80%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E5%BE%88%E5%A4%9Aapache%E7%9A%84%E9%A1%B6%E7%BA%A7%E9%A1%B9%E7%9B%AE" target="_blank" rel="noopener">http://www.apache.org/index.html#projects-list，在这个网址，可以看到很多apache的顶级项目</a>.</li>
</ul>
<h1 id="22-hadoop软件版本">2.2、hadoop软件版本</h1>
<p>1.X		企业不用<br>
2.X		主流版本    CDH5.X<br>
3.X		尝试使用    CDH6.X</p>
<p>很多公司都是使用CDH5.X部署的大数据环境（<a href="http://www.cloudera.com" target="_blank" rel="noopener">www.cloudera.com</a>）<br>
本次课程使用的软件是hadoop-2.6.0-cdh5.16.2/，cdh的这个版本开源媲美apache2.9，因为hadoop-2.6.0-cdh5.16.2，cloudera公司打了很多补丁，如何查看这个版本发生的变化：<a href="http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.16.2.CHANGES.txt%EF%BC%9B" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.16.2.CHANGES.txt；</a><br>
对于升级版本，要去确认新版本有没有解决bug，否则会出现bug发生无法回滚旧版本的尴尬。<br>
<img src="http://hadoop001/GithubBlogPicture/hadoop001/1.png" alt="image"></p>
<ul>
<li>apache软件是开源的，基本没什么人维护，都是cloudera公司的人去升级补丁的；hadoop-2.6.0-cdh5.16.2媲美apache-2.9.0</li>
<li>eg：使用apache部署很麻烦，cloudera公司做了一套傻瓜式的简单部署，无论开发还是运维劳动力成本低；CDH5.X版本对应的是hadoop2.6.0版本，不等价于apache hadoop2.6.0。</li>
</ul>
<p>使用hadoop2.6.0-cdh5.16.2的好处？不必考虑版本兼容性</p>
<h1 id="23-hadoop软件主要分为三个组成部分">2.3、Hadoop软件主要分为三个组成部分</h1>
1、hdfs：存储		分布式文件系统.
2、mapreduce：计算，是由Java代码开发的，企业不用；由于开发难度高，代码量大，维护困难，计算慢，所以大家基本不使用MR，基本使用hive sql、spark、flink，mapreduce引申出来的框架由Hive、Spark，所以MapReduce的思想一定要知道。
3、yarn：资源（CPU 、主要是内存(memory)、VCORE）和作业调度.
<p>大数据都是海量的数据，我们需要进行分布式的文件存储，比如1000台机器，怎么进行分布式存储和管理呢？对于海量数据过来，首先是要进行存储，然后进行mapreduce计算。</p>
<ul>
<li>思考一个问题：正常做开发，数据采集过来，进行计算，产生job1、job2，作业是由yarn来进行调度的。</li>
<li>也有可能从hdfs抽取数据，计算完后，再回写到hdfs</li>
</ul>
<h2 id="小结">小结：</h2>
<ul>
<li>目前公司都是用Spark、Hive、Flink进行开发。</li>
</ul>
<p><strong>前置软件</strong>：<br>
1、hadoop-2.6.0-cdh5.7.0<br>
2、jdk1.7.0_45<br>
3、sshd<br>
jdk安装注意点：解压后查看用户用户组。<br>
<a href="https://blog.csdn.net/zhikanjiani/article/details/89378841" target="_blank" rel="noopener">https://blog.csdn.net/zhikanjiani/article/details/89378841</a></p>
<h1 id="24-hadoop下载方式">2.4、hadoop下载方式</h1>
<p>1、<a href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/</a><br>
CTRL+F：Hadoop-2.6.0-cdh5.7.0.tar.gz，搜索到后单击进行下载。</p>
<p>2、使用wget下载：<br>
wget <a href="http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.16.2.tar.gz" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.16.2.tar.gz</a></p>
<p><img src="https://img-blog.csdnimg.cn/20190418154142733.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poaWthbmppYW5p,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>下载解压完后，做一个软连接：方便以后软件迭代和文件转移。<br>
ln -s hadoop-2.6.0-cdh5.16.2/ hadoop</p>
<h1 id="三-hdfs部署环境">三、hdfs部署环境</h1>
学习都是伪分布式部署：意思是只要1台机器就够了。
<p>3.1、 Purpose：</p>
<p>1、This document describes how to set up and configure a single-node Hadoop installation so that you can quickly perform simple operations using Hadoop MapReduce and the Hadoop Distributed File System (HDFS).</p>
<p>3.2、 软件要求：<br>
<a href="https://cwiki.apache.org/confluence/display/HADOOP2/HadoopJavaVersions" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/HADOOP2/HadoopJavaVersions</a></p>
<p>注意：有些jdk是会有问题的，在部署的时候可能没问题，在J总公司生产上，mysql-jdbc jar包的问题导致内存泄漏，在生产上严格按照要求来，根据推荐版本来操作。</p>
<p>ssh服务我们肯定是安装的，否则我们都无法使用SecureCRT软件来进行远程连接。</p>
<p>我们的主要生产系统使用的就是CentOS6.X和CentOS7.X</p>
<p>3.3、 开始部署：<br>
<strong>第一步：增加hadoop用户：</strong></p>
<ul>
<li>useradd hadoop</li>
</ul>
<p><strong>第二步：创建目录mkdir app</strong></p>
<p><strong>第三步：rz上传或者wget下载</strong></p>
<p><strong>第四步：部署jdk</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">1、root用户下：cd /usr/java目录，rz命令上传，</span><br><span class="line">tar -xzvf jdk-8u45-linux-x64.gz</span><br><span class="line">解压完后注意使用ll查看用户和用户组：</span><br><span class="line"></span><br><span class="line">2、配置全局或者个人环境变量，</span><br><span class="line">全局环境变量：vi  /etc/profile  效果如下所示：</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_45</span><br><span class="line">#export JAVA_HOME=/usr/java/jdk1.8.0_45</span><br><span class="line">export JRE_HOME=$JAVA_HOME/jre</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH</span><br><span class="line">export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">2、完成后注意：source生效</span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br><span class="line">3、扩展：新建/usr/shar/java目录</span><br><span class="line">mkdir  /usr/share/java  </span><br><span class="line">目的 ：CDH环境下部署mysql jdbc jar 包</span><br></pre></td></tr></table></figure>
<p>注意：以后凡是使用到解压都需要使用ll查看下用户及用户组。</p>
<p>扩充：</p>
<ul>
<li>我们解压后发现的jdk的用户是10，使用这个命令：cat /etc/passwd|grep 10</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop java]# cat /etc/passwd|grep 10</span><br><span class="line">games:x:12:100:games:/usr/games:/sbin/nologin</span><br><span class="line">hadoop:x:1000:1000::/home/hadoop:/bin/bash</span><br></pre></td></tr></table></figure>
 <h1 id="三-hdfs部署环境账户当前不可用的解决办法this-account-is-currently-not-available">三、hdfs部署环境账户当前不可用的解决办法（This account is currently not available.）</h1>
<p>1、只要把结尾的  /sbin/nologin改为/bin/bash即可。</p>
<p>2、想要让用户不能登录也这样操作即可：把/bin/bash改为/sbin/nologin即可。</p>
<p>扩展二：</p>
<p>CDH：</p>
<table>
<thead>
<tr>
<th>组件</th>
<th>用户</th>
</tr>
</thead>
<tbody>
<tr>
<td>hdfs</td>
<td>hdfs</td>
</tr>
<tr>
<td>yarn</td>
<td>yarn</td>
</tr>
<tr>
<td>zookeeper</td>
<td>zookeeper</td>
</tr>
<tr>
<td>hbase</td>
<td>hbase</td>
</tr>
</tbody>
</table>
<p>在生产上，su - zookeeper切不了，生产是如何做的？</p>
<ul>
<li>说穿了就是把/sbin/nologin改为/bin/bash即可。</li>
</ul>
<h1 id="四-hdfs伪分布式部署">四、hdfs伪分布式部署</h1>
 **1、增加hadoop用户：**
 - useradd Hadoop
 统一使用Hadoop用户：mkdir app(存放软件) data software
<p><strong>2、解压hadoop软件：hadoop-2.6.0-cdh5.16.2.tar.gz</strong></p>
<ul>
<li>tar -xzvf  hadoop-2.6.0-cdh5.16.2.tar.gz<br>
配置环境变量：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hadoop/app/hadoop-2.6.0-cdh5.16.2</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<p><strong>3、解压后的hadoop软件目录解读：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop hadoop-2.6.0-cdh5.16.2]$ ll</span><br><span class="line">total 76</span><br><span class="line">drwxr-xr-x  2 hadoop hadoop  4096 Mar 24  2016 bin			可执行脚本</span><br><span class="line">drwxr-xr-x  2 hadoop hadoop  4096 Mar 24  2016 bin-mapreduce1</span><br><span class="line">drwxr-xr-x  3 hadoop hadoop  4096 Mar 24  2016 cloudera</span><br><span class="line">drwxr-xr-x  6 hadoop hadoop  4096 Mar 24  2016 etc			配置目录（conf）</span><br><span class="line">drwxr-xr-x  5 hadoop hadoop  4096 Mar 24  2016 examples</span><br><span class="line">drwxr-xr-x  3 hadoop hadoop  4096 Mar 24  2016 examples-mapreduce1</span><br><span class="line">drwxr-xr-x  2 hadoop hadoop  4096 Mar 24  2016 include</span><br><span class="line">drwxr-xr-x  3 hadoop hadoop  4096 Mar 24  2016 lib			jar包目录</span><br><span class="line">drwxr-xr-x  2 hadoop hadoop  4096 Mar 24  2016 libexec</span><br><span class="line">-rw-r--r--  1 hadoop hadoop 17087 Mar 24  2016 LICENSE.txt</span><br><span class="line">-rw-r--r--  1 hadoop hadoop   101 Mar 24  2016 NOTICE.txt</span><br><span class="line">-rw-r--r--  1 hadoop hadoop  1366 Mar 24  2016 README.txt</span><br><span class="line">drwxr-xr-x  3 hadoop hadoop  4096 Mar 24  2016 sbin			hadoop组件的启动，停止脚本</span><br><span class="line">drwxr-xr-x  4 hadoop hadoop  4096 Mar 24  2016 share</span><br><span class="line">drwxr-xr-x 17 hadoop hadoop  4096 Mar 24  2016 src</span><br></pre></td></tr></table></figure>
<p><strong>4、在etc/hadoop/目录下进行逐一配置：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop004 hadoop]$ <span class="built_in">pwd</span></span><br><span class="line">/home/hadoop/app/hadoop/etc/hadoop</span><br><span class="line">[hadoop@hadoop004 hadoop]$ ll</span><br><span class="line">total 152</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  4436 Mar 24  2016 capacity-scheduler.xml</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  1335 Mar 24  2016 configuration.xsl</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop   318 Mar 24  2016 container-executor.cfg</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop   904 Apr 18 02:38 core-site.xml</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  3670 Mar 24  2016 hadoop-env.cmd</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  4333 Apr 18 03:04 hadoop-env.sh</span><br></pre></td></tr></table></figure>
<p><strong>1、  vi  <a href="http://hadoop-env.sh" target="_blank" rel="noopener">hadoop-env.sh</a> 编辑如下：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">The java implementation to use.</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.7.0_45</span><br><span class="line"><span class="comment">#export JAVA_HOME=/usr/java/jdk1.8.0_45</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_PREFIX=/home/hadoop/app/hadoop-2.6.0-cdh5.7.0</span><br></pre></td></tr></table></figure>
<h2 id="拥有三种模式仅作了解">拥有三种模式仅作了解：</h2>
<p>1、Standalone Operation<br>
2、Pseudo-Distributed Operation<br>
3、Fully-Distributed Operation</p>
<p>注意一句话关于Pseudo-Distributed Operation：</p>
<ul>
<li>Hadoop can also be run on a single-node in a pseudo-distributed mode where each hadoop daemon runs in a separate Java process（每一个Hadoop进程都是可以以一个Java进程来运行的）.</li>
</ul>
<p><strong>2、 vi   core-site.xml</strong></p>
<p>路径位置：/home/hadoop/app/hadoop/etc/hadoop/core-site.xml，编辑如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">etc/hadoop/core-site.xml:</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;		//localhost可以写当前部署环境机器的IP，如果是阿里云主机配置内网IP</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p><strong>3、 vi hdfs-site.xml</strong></p>
<p>路径位置：/home/hadoop/app/hadoop/etc/hadoop/hdfs-site.xml，编辑如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">etc/hadoop/hdfs-site.xml:</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h1 id="41-单台机器的无密码访问">4.1、单台机器的无密码访问</h1>
<p>1、当前使用hadoop用户，使用root用户会有问题，在hadoop用户下ssh localhost date会出现问题，Permission denied, please try again.<br>
<img src="https://img-blog.csdnimg.cn/20191015160630898.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poaWthbmppYW5p,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
此处跟着若泽数据进行如下操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1、进入~目录：</span><br><span class="line">[hadoop@hadoop004 hadoop]$ cd ~</span><br><span class="line">[hadoop@hadoop004 ~]$ ll -a</span><br><span class="line">total 52</span><br><span class="line">drwx------. 2 hadoop hadoop 4096 Apr 18 02:42 .ssh</span><br><span class="line"></span><br><span class="line">2、删除系统原有的.ssh文件</span><br><span class="line">rm -rf .ssh</span><br><span class="line"></span><br><span class="line">3、ssh-keygen 生成密钥文件，三个回车okay</span><br><span class="line"></span><br><span class="line">4、进入到.ssh目录下，查看到有如下几个文件：id_rsa(私有密钥)、id_rsa.pub（公钥）；</span><br><span class="line">cat id_rsa.pub &gt;&gt; authorized_keys，把公钥文件追加到authorized_keys；</span><br><span class="line"></span><br><span class="line">5、chmod -R 600 authorized_keys    赋予此文件600权限，在cdh官网上未做体现，但是在Apache官网上有写，网址如下：http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html</span><br><span class="line"></span><br><span class="line">6、此时进行测试：ssh localhost date</span><br><span class="line">首次通信输入yes，测试无问题如下：</span><br><span class="line">[hadoop@hadoop004 .ssh]$ ssh localhost date</span><br><span class="line">Thu Apr 18 05:06:30 HKT 2019</span><br></pre></td></tr></table></figure>
<p>注意：上述操作步骤使用的是hadoop用户，不是root用户。</p>
<h1 id="42-准备启动hadoop">4.2、准备启动Hadoop</h1>
1、启动前首先需要格式化namenode：
- bin/hdfs namenode -format，出现successfully formatted则表示成功.
![在这里插入图片描述](https://img-blog.csdnimg.cn/20191015161229307.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poaWthbmppYW5p,size_16,color_FFFFFF,t_70)
<p><strong>2、命令start-dfs.sh来启动hadoop:</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop004 hadoop]$ start-dfs.sh</span><br><span class="line">[hadoop@hadoop004 hadoop]$ jps</span><br><span class="line">52531 SecondaryNameNode</span><br><span class="line">52629 Jps</span><br><span class="line">52411 DataNode</span><br><span class="line">52319 NameNode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">单节点启动NameNode</span><br><span class="line">sbin/hadoop-daemon.sh start NameNode</span><br><span class="line">单节点启动SecondaryNameNode和DataNode：</span><br><span class="line">命令是一样的：</span><br><span class="line">hadoop-daemon.sh start secondarynamenode</span><br><span class="line">hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure>
<h1 id="43-hadoop日志信息解读">4.3、hadoop日志信息解读</h1>
<p><strong>启动日志信息如下：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop hadoop-2.6.0-cdh5.7.0]$ start-dfs.sh</span><br><span class="line">19/10/15 16:24:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">Starting namenodes on [hadoop]</span><br><span class="line">The authenticity of host <span class="string">'hadoop (172.16.56.88)'</span> can<span class="string">'t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is 8e:8d:a4:95:50:cc:40:d6:e5:51:0f:84:a8:7b:ce:ef.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">hadoop: Warning: Permanently added '</span>hadoop,172.16.56.88<span class="string">' (ECDSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">hadoop: starting namenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-namenode-hadoop.out</span></span><br><span class="line"><span class="string">localhost: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-hadoop.out</span></span><br><span class="line"><span class="string">Starting secondary namenodes [0.0.0.0]</span></span><br><span class="line"><span class="string">The authenticity of host '</span>0.0.0.0 (0.0.0.0)<span class="string">' can'</span>t be established.</span><br><span class="line">ECDSA key fingerprint is 8e:8d:a4:95:50:cc:40:d6:e5:51:0f:84:a8:7b:ce:ef.</span><br><span class="line">Are you sure you want to <span class="built_in">continue</span> connecting (yes/no)? yes</span><br><span class="line">0.0.0.0: Warning: Permanently added <span class="string">'0.0.0.0'</span> (ECDSA) to the list of known hosts.</span><br><span class="line">0.0.0.0: starting secondarynamenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-secondarynamenode-hadoop.out</span><br><span class="line">19/10/15 16:25:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">[hadoop@hadoop hadoop-2.6.0-cdh5.7.0]$ jps</span><br><span class="line">4182 SecondaryNameNode</span><br><span class="line">4313 Jps</span><br><span class="line">3933 NameNode</span><br><span class="line">4028 DataNode</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20191015162711673.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poaWthbmppYW5p,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>解释：<br>
1、starting namenodes说明namenode可以启动多个，我们当前只部署了一个</p>
<p>2、localhost来启动datanode，localhost都已经配置了无密码信任关系</p>
<p>3、secondarynamenode在0.0.0.0这个机器上启动的，说白了其实还是在当前机器上启动的，只是信任关系配置的是localhost</p>
<p>4、为什么要配置ssh信任关系，启动secondarynamenode是在0.0.0.0上，第一次要输入yes，</p>
<p>secondarynamenode信任关系输入yes后，会在known_hosts中创建一条记录；<br>
当我们输入ssh localhost date，首先会去authorized_keys这个文件中去找hadoop用户：hadoop机器已经配置了一个密钥，相当于用户暴露的一个公钥文件；authorized_keys可以放其它机器的文件。</p>
<p>ssh loclahost首先回去suthorized_keys中去找，找不到的话会让我们输入yes，因为known_hosts中没有这条记录，为什么不用输入密码？公钥文件放到了信任文件中（authorized_keys）</p>
<p>思考：为什么要配置ssh localhost，因为在启动的时候是需要ssh的。</p>
<p>出现的问题？</p>
<p>J总部署的时候：datanode进程没有起来，解决：cd /tmp目录下，rm -rf hadoop-hadoop，里面有datanode的地址；这时重新格式化namenode，bin/hdfs namenode -format，再次尝试重新启动，没有问题。</p>
<h1 id="44-web-ui界面查看">4.4、Web UI界面查看</h1>
<ul>
<li>网址：<a href="http://47.98.238.163:50070/dfshealth.html#tab-overview" target="_blank" rel="noopener">http://47.98.238.163:50070/dfshealth.html#tab-overview</a></li>
<li>在core-site中配置的是阿里云内网IP，浏览器访问的时候使用的是外网IP+50070端口。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20191015165849184.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poaWthbmppYW5p,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<table>
<thead>
<tr>
<th>NameNode</th>
<th>SecondaryNameNode</th>
<th>DataNode</th>
</tr>
</thead>
<tbody>
<tr>
<td>名称节点</td>
<td>第二名称节点</td>
<td>数据节点</td>
</tr>
<tr>
<td>老大</td>
<td>老二</td>
<td>小弟</td>
</tr>
</tbody>
</table>
<p>对于hdfs如何理解？</p>
<ul>
<li>正常的电脑是一个物理机，我们在物理机上装了一个linux系统，理解为做存储用，部署文件脚本；部署hdfs的意思是，在linux系统上又部署了一个hdfs，hdfs也是一个做存储的；linux系统是从根目录 / 开始的，hdfs也是从根目录 / 开始的。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20191015171108629.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poaWthbmppYW5p,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li>相当于我们在windows上划分了40G部署了一个VM虚拟机，在虚拟机上又划了一小块做hdfs，这是一个嵌套的东西。</li>
</ul>
<p>关于hdfs的一些相关命令请参考楼主的其它博客：</p>
<ul>
<li><a href="https://blog.csdn.net/zhikanjiani/article/details/100039072" target="_blank" rel="noopener">https://blog.csdn.net/zhikanjiani/article/details/100039072</a></li>
</ul>
<p>HDFS命令和linux命令极其相似：</p>
<ul>
<li>hdfs命令能够出来是因为在~/.bash_profile中已经配置好了的原因，否则我们需要补全路径；不补全的话从环境变量中读取是读不到的。</li>
</ul>
<h1 id="五-作业">五、作业</h1>
1、ssh博客、阅读、摘抄
<p>2、部署hdfs伪分布式并写博客</p>

                

                <hr>
                <!-- Pager -->
                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/article/MySQL部署/" data-toggle="tooltip" data-placement="top" title="MySQL部署">&larr; Previous Post</a>
                        </li>
                    
                    
                        <li class="next">
                            <a href="/article/Linux命令一/" data-toggle="tooltip" data-placement="top" title="Linux命令一">Next Post &rarr;</a>
                        </li>
                    
                </ul>

                <br>

                <!--打赏-->
                
                <!--打赏-->

                <br>
                <!--分享-->
                
                    <div class="social-share"  data-wechat-qrcode-helper="" align="center"></div>
                    <!--  css & js -->
                    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
                    <script src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>
                
                <!--分享-->
                <br>                       
                
                <!-- require APlayer -->
                

                <!-- duoshuo Share start -->
                
                <!-- 多说 Share end-->

                <!-- 多说评论框 start -->
                
                <!-- 多说评论框 end -->

                <!-- disqus comment start -->
                
                <!-- disqus comment end -->

                

            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

  
    
      <aside id="sidebar">
        <div id="toc" class="toc-article">
        <strong class="toc-title">Contents</strong>
        
          <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#一-上次课课程回顾"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">&#x4E00;&#x3001;&#x4E0A;&#x6B21;&#x8BFE;&#x8BFE;&#x7A0B;&#x56DE;&#x987E;</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#二-hadoop入门介绍"><span class="toc-nav-number">2.</span> <span class="toc-nav-text">&#x4E8C;&#x3001;hadoop&#x5165;&#x95E8;&#x4ECB;&#x7ECD;</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#21-概念"><span class="toc-nav-number">3.</span> <span class="toc-nav-text">2.1&#x3001;&#x6982;&#x5FF5;</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#22-hadoop软件版本"><span class="toc-nav-number">4.</span> <span class="toc-nav-text">2.2&#x3001;hadoop&#x8F6F;&#x4EF6;&#x7248;&#x672C;</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#23-hadoop软件主要分为三个组成部分"><span class="toc-nav-number">5.</span> <span class="toc-nav-text">2.3&#x3001;Hadoop&#x8F6F;&#x4EF6;&#x4E3B;&#x8981;&#x5206;&#x4E3A;&#x4E09;&#x4E2A;&#x7EC4;&#x6210;&#x90E8;&#x5206;</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#小结"><span class="toc-nav-number">5.1.</span> <span class="toc-nav-text">&#x5C0F;&#x7ED3;&#xFF1A;</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#24-hadoop下载方式"><span class="toc-nav-number">6.</span> <span class="toc-nav-text">2.4&#x3001;hadoop&#x4E0B;&#x8F7D;&#x65B9;&#x5F0F;</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#三-hdfs部署环境"><span class="toc-nav-number">7.</span> <span class="toc-nav-text">&#x4E09;&#x3001;hdfs&#x90E8;&#x7F72;&#x73AF;&#x5883;</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#三-hdfs部署环境账户当前不可用的解决办法this-account-is-currently-not-available"><span class="toc-nav-number">8.</span> <span class="toc-nav-text">&#x4E09;&#x3001;hdfs&#x90E8;&#x7F72;&#x73AF;&#x5883;&#x8D26;&#x6237;&#x5F53;&#x524D;&#x4E0D;&#x53EF;&#x7528;&#x7684;&#x89E3;&#x51B3;&#x529E;&#x6CD5;&#xFF08;This account is currently not available.&#xFF09;</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#四-hdfs伪分布式部署"><span class="toc-nav-number">9.</span> <span class="toc-nav-text">&#x56DB;&#x3001;hdfs&#x4F2A;&#x5206;&#x5E03;&#x5F0F;&#x90E8;&#x7F72;</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#拥有三种模式仅作了解"><span class="toc-nav-number">9.1.</span> <span class="toc-nav-text">&#x62E5;&#x6709;&#x4E09;&#x79CD;&#x6A21;&#x5F0F;&#x4EC5;&#x4F5C;&#x4E86;&#x89E3;&#xFF1A;</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#41-单台机器的无密码访问"><span class="toc-nav-number">10.</span> <span class="toc-nav-text">4.1&#x3001;&#x5355;&#x53F0;&#x673A;&#x5668;&#x7684;&#x65E0;&#x5BC6;&#x7801;&#x8BBF;&#x95EE;</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#42-准备启动hadoop"><span class="toc-nav-number">11.</span> <span class="toc-nav-text">4.2&#x3001;&#x51C6;&#x5907;&#x542F;&#x52A8;Hadoop</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#43-hadoop日志信息解读"><span class="toc-nav-number">12.</span> <span class="toc-nav-text">4.3&#x3001;hadoop&#x65E5;&#x5FD7;&#x4FE1;&#x606F;&#x89E3;&#x8BFB;</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#44-web-ui界面查看"><span class="toc-nav-number">13.</span> <span class="toc-nav-text">4.4&#x3001;Web UI&#x754C;&#x9762;&#x67E5;&#x770B;</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#五-作业"><span class="toc-nav-number">14.</span> <span class="toc-nav-text">&#x4E94;&#x3001;&#x4F5C;&#x4E1A;</span></a></li></ol>
        
        </div>
      </aside>
    

                
            <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#ruozedata" title="ruozedata">ruozedata</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">

                    
                        <li><a href="http://www.ruozedata.com" target="_blank">若泽数据官网</a></li>
                    
                </ul>
                
            </div>
        </div>
    </div>
</article>








<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'left',
          icon: 'rz'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>


<!-- chrome Firefox 中文锚点定位失效-->
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.js"></script>
<!-- smooth scroll behavior polyfill  -->
<script type="text/javascript" src="/js/smoothscroll.js"></script>
<script>
        $('#toc').on('click','a',function(a){
            // var isChrome = window.navigator.userAgent.indexOf("Chrome") !== -1;
            // console.log(window.navigator.userAgent,isChrome)
                // if(isChrome) {
                    // console.log(a.currentTarget.outerHTML);
                    // console.log($(a.currentTarget).attr("href"));
                    //跳转到指定锚点
                    // document.getElementById(a.target.innerText.toLowerCase()).scrollIntoView(true);
                    document.getElementById($(a.currentTarget).attr("href").replace("#","")).scrollIntoView({behavior: 'smooth' });
                // }
        })  
</script>


    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                
                

                

                

                
                    <li>
                        <a target="_blank"  href="https://github.com/hackeruncle">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; John 2019 
                    By <a href="http://www.ruozedata.com">若泽数据，企业在职</a> | BigData
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=ruozedata&repo=Bigdata&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("http://www.ruozedata.com/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'UA-XXXXXXXX-X';
    var _gaDomain = 'yoursite';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Baidu Tongji -->

<script>
    // dynamic User by Hux
    var _baId = 'xxx';

    // Originial
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?" + _baId;
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
</script>






	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>
<!-- Image to hack wechat -->
<img src="http://www.ruozedata.com/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
